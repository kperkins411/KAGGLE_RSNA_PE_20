{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "Added a preconverted jpg data library to kernel from https://www.kaggle.com/vaillant/discussion see explanation for RGB channels<BR>\n",
    "Starter code from https://www.kaggle.com/orkatz2/pulmonary-embolism-pytorch-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T14:34:08.185192Z",
     "start_time": "2020-10-23T14:34:08.173646Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import functools\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import gc\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import pydicom\n",
    "from snippets import reduce_mem_usage\n",
    "from snippets import config\n",
    "from snippets import transforms_val\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "torch.save(model,'./resnet18.pth')\n",
    "model=torch.load('./resnet18.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features,config.numb_classes)\n",
    "\n",
    "#it was saved on GPU, load it on CPU\n",
    "model.load_state_dict(torch.load(config.MODEL_PARAMS_LOC, map_location=torch.device(dev)))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T14:34:08.230048Z",
     "start_time": "2020-10-23T14:34:08.190468Z"
    }
   },
   "outputs": [],
   "source": [
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "# !jupyter labextension install @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T14:34:08.250100Z",
     "start_time": "2020-10-23T14:34:08.232975Z"
    }
   },
   "outputs": [],
   "source": [
    "#where the data is\n",
    "PATH = '../input/rsna-str-pulmonary-embolism-detection'\n",
    "PATH_TEST=PATH+'/test'\n",
    "\n",
    "DO_SMALL_TEST=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T16:10:04.605360Z",
     "start_time": "2020-10-21T16:10:04.600249Z"
    }
   },
   "source": [
    "## Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1694054   96540\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "if (DO_SMALL_TEST is True): \n",
    "    ## TRAINING DATA CHECK\n",
    "\n",
    "    train_df = pd.read_csv(\"../input/rsna-str-pulmonary-embolism-detection/train.csv\")\n",
    "    # train_df = reduce_mem_usage(train_df)\n",
    "    # train_df[ train_df['pe_present_on_image']==1]\n",
    "\n",
    "    df0 = train_df[train_df['pe_present_on_image']==0]\n",
    "    df1 = train_df[train_df['pe_present_on_image']==1]\n",
    "    print( str(len(df0))+\"   \" + str(len(df1)))\n",
    "\n",
    "    test_df = pd.concat([df0[:5000],df1[:5000]],axis=0)\n",
    "    print(len(test_df))\n",
    "\n",
    "    test_df[test_df['pe_present_on_image']==1].head()\n",
    "\n",
    "    #if using train then indicate that you look in train dir\n",
    "    jpeg_dir = '../input/rsna-str-pe-detection-jpeg-256/train-jpegs'\n",
    "    PATH_TEST=jpeg_dir\n",
    "else:\n",
    "    test_df = pd.read_csv(\"../input/rsna-str-pulmonary-embolism-detection/test.csv\",dtype={'StudyInstanceUID':'string', 'SeriesInstanceUID':'string', 'SOPInstanceUID':'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T14:34:08.432662Z",
     "start_time": "2020-10-23T14:34:08.269263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "listOfStudyID = test_df['StudyInstanceUID'].unique()\n",
    "print(len(listOfStudyID))\n",
    "print(len(test_df))\n",
    "\n",
    "# test_df.head()\n",
    "# test_df.describe()pydicom\n",
    "# test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T14:34:10.920541Z",
     "start_time": "2020-10-23T14:34:10.816863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StudyInstanceUID              object\n",
       "SeriesInstanceUID             object\n",
       "SOPInstanceUID                object\n",
       "pe_present_on_image            int64\n",
       "negative_exam_for_pe           int64\n",
       "qa_motion                      int64\n",
       "qa_contrast                    int64\n",
       "flow_artifact                  int64\n",
       "rv_lv_ratio_gte_1              int64\n",
       "rv_lv_ratio_lt_1               int64\n",
       "leftsided_pe                   int64\n",
       "chronic_pe                     int64\n",
       "true_filling_defect_not_pe     int64\n",
       "rightsided_pe                  int64\n",
       "acute_and_chronic_pe           int64\n",
       "central_pe                     int64\n",
       "indeterminate                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()\n",
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T04:52:05.389312Z",
     "start_time": "2020-10-23T04:52:05.381904Z"
    }
   },
   "outputs": [],
   "source": [
    "from snippets import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T04:52:05.400764Z",
     "start_time": "2020-10-23T04:52:05.390248Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_df, batch_size=config.batch_size*2, shuffle=False, num_workers=config.WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T04:52:05.419930Z",
     "start_time": "2020-10-23T04:52:05.401723Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# listOfStudyID[0]\n",
    "# thisStudyDF = test_df[test_df['StudyInstanceUID']==listOfStudyID[0]]\n",
    "# len(thisStudyDF)\n",
    "# # thisStudyDF\n",
    "\n",
    "# eachImageID=thisStudyDF.index[0]\n",
    "# import pydicom\n",
    "\n",
    "# # eachImagePath = '../input/rsna-str-pulmonary-embolism-detection/test/'+test_df.loc[eachImageID, 'StudyInstanceUID']+'/'+test_df.loc[eachImageID, 'SeriesInstanceUID']+'/'+eachImageID+'.dcm'\n",
    "# eachImagePath = '../input/rsna-str-pulmonary-embolism-detection/test/00268ff88746/75d23269adbd/012c12fe09c3.dcm'\n",
    "# dcm_data = pydicom.dcmread(eachImagePath)\n",
    "# image = dcm_data.pixel_array * int(dcm_data.RescaleSlope) + int(dcm_data.RescaleIntercept)\n",
    "# image = np.stack([test_dataset._window(image, WL=-600, WW=1500),\n",
    "#                   test_dataset._window(image, WL=40, WW=400),\n",
    "#                   test_dataset._window(image, WL=100, WW=700)], 2)\n",
    "\n",
    "# print(image.shape)\n",
    "# # image = image.astype(np.float32)\n",
    "# image = preprocessing_val(image)\n",
    "# toPred = image.unsqueeze(0)\n",
    "# print(image.shape)\n",
    "# # z = model(toPred)\n",
    "# # pred = torch.sigmoid(z)\n",
    "# # pred1 = pred.detach().numpy().astype('float32')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T04:52:05.439582Z",
     "start_time": "2020-10-23T04:52:05.429157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#where should it go\n",
    "dev = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T04:52:05.641128Z",
     "start_time": "2020-10-23T04:52:05.440481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model that was just trained\n",
    "#and do following inference with it\n",
    "model = models.resnet18(pretrained=True)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features,config.numb_classes)\n",
    "\n",
    "#it was saved on GPU, load it on CPU\n",
    "model.load_state_dict(torch.load(config.MODEL_PARAMS_LOC, map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction generator\n",
    "\n",
    "Goes in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T04:52:05.662991Z",
     "start_time": "2020-10-23T04:52:05.651809Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# exam_level_features = ['negative_exam_for_pe', 'rv_lv_ratio_gte_1', 'rv_lv_ratio_lt_1',\n",
    "#                        'leftsided_pe',         'chronic_pe',        'rightsided_pe', \n",
    "#                        'acute_and_chronic_pe', 'central_pe',        'indeterminate']\n",
    "\n",
    "# #create columns\n",
    "# index = ['StudyInstanceUID']\n",
    "\n",
    "# all = (index)\n",
    "# all.extend(exam_level_features)\n",
    "\n",
    "# #create dict of unique StudyInstanceUID\n",
    "# studies={'StudyInstanceUID':listOfStudyID}\n",
    "\n",
    "# totals_per_series = pd.DataFrame(studies,columns=all).fillna(0.0)\n",
    "\n",
    "# %time\n",
    "# from snippets import SInstUID_tracker\n",
    "\n",
    "# import time\n",
    "# start_time = time.perf_counter()\n",
    " \n",
    "# f = open('submission.csv', 'w')\n",
    "# f.write('id,label\\n')\n",
    "\n",
    "# sidt = SInstUID_tracker(test_df )\n",
    "# imgs_processed=0\n",
    "\n",
    "# # dev = 'cpu'\n",
    "# model.to(dev)\n",
    "# with torch.no_grad():\n",
    "\n",
    "#     for eachStudyID in tqdm(listOfStudyID):\n",
    "        \n",
    "#         #get one study\n",
    "#         thisStudyDF = test_df[test_df['StudyInstanceUID']==eachStudyID]\n",
    "        \n",
    "#         #create a dataset from that study\n",
    "#         test_dataset = CTDatasetDicom(thisStudyDF,path= PATH_TEST, transforms=transforms_val)\n",
    "        \n",
    "#         #create a dataloader for just that study\n",
    "#         test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=config.WORKERS, pin_memory=True)        \n",
    "# #         test_dataloader = DataLoader(test_dataset, batch_size=config.batch_size*4, shuffle=False, num_workers=config.WORKERS, pin_memory=True)\n",
    "# #         tqdm_loader = tqdm(test_dataloader)\n",
    "#         for idx, images in enumerate(test_dataloader):\n",
    "#             images=images.to(dev)\n",
    "# #             print(len(images))\n",
    "            \n",
    "#             pred=model(images)\n",
    "#             pred = torch.sigmoid(pred)\n",
    "            \n",
    "#             print(pred)\n",
    "#             raise\n",
    "            \n",
    "#             imgs_processed+=64\n",
    "#             if(imgs_processed>1000):\n",
    "#                 elapsed_time = time.perf_counter() - start_time\n",
    "#                 tpall =((elapsed_time/1000.0)*1500000)/60.0\n",
    "#                 print(f'time to do 1.5 million images {tpall:0.4f} minutes')\n",
    "                #its 574 minutes for CPU\n",
    "                #its 111 minutes with bathcsize of 64 on GPU\n",
    "                #with only 1 data_loader for the whole set its 90 minutes\n",
    "#             print(pred)\n",
    "#             raise\n",
    "            \n",
    "            \n",
    "            \n",
    "#         for eachImageID in thisStudyDF.index:\n",
    "            \n",
    "# #             try:\n",
    "#                 eachImagePath = '../input/rsna-str-pulmonary-embolism-detection/test/'+test_df.loc[eachImageID, 'StudyInstanceUID']+'/'+test_df.loc[eachImageID, 'SeriesInstanceUID']+'/'+eachImageID+'.dcm'\n",
    "#                 dcm_data = dcmread(eachImagePath)\n",
    "#                 image = dcm_data.pixel_array * int(dcm_data.RescaleSlope) + int(dcm_data.RescaleIntercept)\n",
    "#                 image = np.stack([window(image, WL=-600, WW=1500),\n",
    "#                                   window(image, WL=40, WW=400),\n",
    "#                                   window(image, WL=100, WW=700)], 2)\n",
    "\n",
    "#                 image = image.astype(np.float32)\n",
    "#                 image = data_transform(image)\n",
    "#                 toPred = image.unsqueeze(0).cuda()\n",
    "#                 z = model(toPred)\n",
    "#                 pred = torch.sigmoid(z)\n",
    "#                 pred = pred.cpu().detach().numpy().astype('float32')[0,0]\n",
    "\n",
    "#             except:\n",
    "#                 pred = defaultScore['_pe_present_on_image']\n",
    "          \n",
    "\n",
    "# df_image_results=pd.DataFrame( columns=['image','pe_present_on_image' ])\n",
    "# df_image_results=df_image_results.append({'image':'1 image', 'pe_present_on_image':5.0}, ignore_index=True)\n",
    "# df_image_results=df_image_results.append({'image':'2 image', 'pe_present_on_image':5.0}, ignore_index=True)\n",
    "# df_image_results=df_image_results.append({'image':'3 image', 'pe_present_on_image':5.0}, ignore_index=True)\n",
    "\n",
    "# df_image_results.head()\n",
    "\n",
    "# df1 = self.df_main[self.df_main[:,3]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../input/rsna-str-pe-detection-jpeg-256/train-jpegs'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick one dataset type\n",
    "from snippets import CTDatasetJPEG, CTDatasetDicom\n",
    "if (DO_SMALL_TEST is True):   \n",
    "    test_dataset = CTDatasetJPEG(test_df,path= PATH_TEST, transforms=transforms_val, mode='val')\n",
    "else:\n",
    "    test_dataset = CTDatasetDicom(test_df,path= PATH_TEST, transforms=transforms_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-23T04:52:05.226Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [03:18<00:00,  4.97s/it]\n"
     ]
    }
   ],
   "source": [
    "from snippets import SInstUID_tracker\n",
    "import time\n",
    "start_time = time.perf_counter()\n",
    " \n",
    "# imgs_processed=0\n",
    "df_image_results=pd.DataFrame( columns=['imageSOP','pe_present_on_image' ])\n",
    "\n",
    "# dev = 'cpu'\n",
    "model.to(dev)\n",
    "with torch.no_grad():      \n",
    "    sidt = SInstUID_tracker(test_df )\n",
    "    \n",
    "    #create a dataloader for just that study\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=config.WORKERS, pin_memory=True)        \n",
    "   \n",
    "    start_time = time.perf_counter()\n",
    "    tqdm_loader = tqdm(test_dataloader)\n",
    "    for idx, (studyids,imageSOP,images,_) in enumerate(tqdm_loader):\n",
    "        images=images.to(dev)\n",
    "\n",
    "        preds=model(images)\n",
    "        preds=torch.sigmoid(preds).cpu()\n",
    "       \n",
    "        for i,pred in enumerate(preds):\n",
    "            pred=pred.numpy()\n",
    "            sidt.record(studyids[i],pred)\n",
    "            #the following line greatly increases time to run from 88 to 104 minutes and it leaks\n",
    "            df_image_results=df_image_results.append({'imageSOP':imageSOP[i], 'pe_present_on_image':preds[0][0]}, ignore_index=True)\n",
    "\n",
    "        del images,studyids,imageSOP\n",
    "        \n",
    "#         imgs_processed+=256\n",
    "#         if(imgs_processed>20000):\n",
    "#             elapsed_time = time.perf_counter() - start_time\n",
    "#             tpall =((elapsed_time/10000.0)*1500000)/60.0\n",
    "#             print(f'time to do 1.5 million images {tpall:0.4f} minutes')\n",
    "\n",
    "# with open('submission.txt' as f):\n",
    "#     f.write(\"info\")\n",
    "#     for each row in sidt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and save a dataframe\n",
    "sidt.df.to_pickle(\"./sidt_df_jpeg.pkl\")\n",
    "\n",
    "sidt_new = SInstUID_tracker(test_df )\n",
    "sidt_new.df= pd.read_pickle(\"./sidt_df_jpeg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageSOP</th>\n",
       "      <th>pe_present_on_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f3cb036d06</td>\n",
       "      <td>tensor(0.0181)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f57ffd3883b6</td>\n",
       "      <td>tensor(0.0181)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41220fda34a3</td>\n",
       "      <td>tensor(0.0181)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13b685b4b14f</td>\n",
       "      <td>tensor(0.0181)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>be0b7524ffb4</td>\n",
       "      <td>tensor(0.0181)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       imageSOP pe_present_on_image\n",
       "0  c0f3cb036d06      tensor(0.0181)\n",
       "1  f57ffd3883b6      tensor(0.0181)\n",
       "2  41220fda34a3      tensor(0.0181)\n",
       "3  13b685b4b14f      tensor(0.0181)\n",
       "4  be0b7524ffb4      tensor(0.0181)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sidt.df.head()\n",
    "df_image_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_study(df, label, fle):\n",
    "    '''\n",
    "    :param df: dataframe with all the studyIDs\n",
    "    :param label: which label we are outputting for\n",
    "    :param fle: where we are outputting to\n",
    "    :return: nada\n",
    "    '''\n",
    "    for index, row in df.iterrows():\n",
    "        fle.write(row['StudyInstanceUID']+\"_\"+label+\",\"+str(row[label]) +'\\n')\n",
    "\n",
    "labels=['negative_exam_for_pe','rv_lv_ratio_gte_1','rv_lv_ratio_lt_1','leftsided_pe','chronic_pe','rightsided_pe','acute_and_chronic_pe', 'central_pe','indeterminate']\n",
    "\n",
    "with open('submission.csv','w') as fle:\n",
    "    fle.write('id,label\\n')\n",
    "\n",
    "    #print out the image and the probs\n",
    "    for label in labels:\n",
    "        out_study(sidt.df, label, fle)\n",
    "\n",
    "    # print out the image and the probs\n",
    "    for index, row in df_image_results.iterrows():\n",
    "        # access data using column names\n",
    "        fle.write(row['imageSOP'] + \",\" + str(row['pe_present_on_image'].item())+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sidt_new.df.shape\n",
    "\n",
    "# sidt.df.describe()\n",
    "\n",
    "# sidt.df[sidt.df['pe_present_on_image']>0.04].sum()\n",
    "\n",
    "# df_image_results.head(200)\n",
    "\n",
    "# f = open('submission.csv', 'w')\n",
    "# f.write('id,label\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# for img, lbl in train_dl:\n",
    "#     print(img[0].shape)\n",
    "#     print(len(lbl[0]))\n",
    "#     break\n",
    "# # tmp=next((train_dl))\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# row = train_dataset.df[0]\n",
    "# print(f\"{jpeg_dir}/{row[0]}/{row[1]}/*{row[2]}.jpg\")\n",
    "# img = cv2.imread(glob.glob(f\"{jpeg_dir}/{row[0]}/{row[1]}/*{row[2]}.jpg\")[0])\n",
    "# plt.imshow(img)#discard\n",
    "\n",
    "#how many?\n",
    "# tot_instances=0\n",
    "\n",
    "# studies=(os.listdir(PATH_TRAIN))\n",
    "# studies=sorted(studies)\n",
    "# print(\"tot_studies= \"+str(len(studies)))\n",
    "\n",
    "# tot_series=0\n",
    "# for study in studies:\n",
    "#     pth=os.path.join(PATH_TRAIN,study)\n",
    "# #     print(pth)\n",
    "#     series=os.listdir(pth)\n",
    "#     tot_series+=len(series)\n",
    "#     for serie in series:\n",
    "#         tot_instances+=len(os.listdir(os.path.join(pth,serie)))\n",
    "# print(\"tot_series= \"+str(tot_series))\n",
    "# print(\"tot_instances= \"+str(tot_instances))\n",
    "\n",
    "\n",
    "# class RsnaDataset(Dataset):\n",
    "    \n",
    "#     def __init__(self,df,transforms):\n",
    "#         super().__init__()\n",
    "#         self.df = df\n",
    "#         self.transforms = transforms\n",
    "    \n",
    "#     def __getitem__(self,index):      \n",
    "#         image_path = self.df.image_paths[index]\n",
    "#         data = self.df[self.df['ImagePath']==image_path]\n",
    "#         labels = data[target_columns].values.reshape(-1)\n",
    "#         image = get_img(image_path)\n",
    "#         image = convert_to_rgb(image)\n",
    "        \n",
    "#         if self.transforms:\n",
    "#             image = self.transforms(image=image)['image']\n",
    "            \n",
    "#         image = torch.tensor(image,dtype=torch.float)        \n",
    "#         labels = torch.tensor(labels,dtype=torch.float)\n",
    "        \n",
    "#         return image,labels\n",
    "           \n",
    "#     def __len__(self):\n",
    "#         return self.image_paths.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T22:02:47.342921Z",
     "start_time": "2020-10-18T22:02:47.341392Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#see what above class does\n",
    "# t_df.head()\n",
    "# df_tmp=t_df.values\n",
    "# df_tmp.shape\n",
    "\n",
    "# df0 = df_tmp[df_tmp[:,3]==0]\n",
    "# df1 = df_tmp[df_tmp[:,3]==1]\n",
    "# print(len(df0))\n",
    "# print(len(df1))\n",
    "\n",
    "# df_tmp_balanced = np.concatenate([df0[:len(df1)],df1],axis=0)\n",
    "# print(len(df_tmp_balanced))\n",
    "# print(sum(df_tmp_balanced[:,3]==0))\n",
    "# print(sum(df_tmp_balanced[:,3]==1))\n",
    "# # df0 = self.df_main[self.df_main[:,3]==0]\n",
    "# #         df1 = self.df_main[self.df_main[:,3]==1]\n",
    "# #         np.random.shuffle(df0)\n",
    "# #         self.df = np.concatenate([df0[:len(df1)],df1],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_training_augmentation(y=256,x=256):\n",
    "# #     train_transform = [albu.RandomBrightnessContrast(p=0.3),\n",
    "# #                            albu.VerticalFlip(p=0.5),\n",
    "# #                            albu.HorizontalFlip(p=0.5),\n",
    "# #                            albu.Downscale(p=1.0,scale_min=0.35,scale_max=0.75,),\n",
    "# #                            albu.Resize(y, x)]\n",
    "#     train_transform = [albu.RandomBrightnessContrast(p=0.3),\n",
    "#                            albu.HorizontalFlip(p=0.5),\n",
    "#                            albu.Resize(y, x)]\n",
    "#     return albu.Compose(train_transform)\n",
    "\n",
    "# def get_validation_augmentation(y=256,x=256):\n",
    "#     \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "#     test_transform = [albu.Resize(y, x)]\n",
    "#     return albu.Compose(test_transform)\n",
    "\n",
    "# formatted_settings = {\n",
    "#             'input_size': [3, 224, 224],\n",
    "#             'input_range': [0, 1],\n",
    "#             'mean': [0.485, 0.456, 0.406],\n",
    "#             'std': [0.229, 0.224, 0.225],}\n",
    "\n",
    "# def preprocess_to_train_format(dcm_data):\n",
    "#     '''\n",
    "#     preprocess the image (numpy array, into same format as the data used to train the model\n",
    "#     x: input image\n",
    "#     '''            #the following increases from 88 to 105 mins\n",
    "\n",
    "#     img = dcm_data.pixel_array * int(dcm_data.RescaleSlope) + int(dcm_data.RescaleIntercept)\n",
    "#     img = np.stack([window(img, WL=-600, WW=1500),\n",
    "#                       window(img, WL=40, WW=400),\n",
    "#                       window(img, WL=100, WW=700)], 2)\n",
    "\n",
    "#     img = image.astype(np.float32)\n",
    "#     return img\n",
    "\n",
    "\n",
    "# def preprocess_input(x, mean=None, std=None, input_space=\"RGB\", input_range=None, **kwargs):\n",
    " \n",
    "#     #flips from BGR to RGB (or vice versa I'm not sure)\n",
    "#     if input_space == \"BGR\":\n",
    "#         x = x[..., ::-1].copy()\n",
    "#         gc.collect()\n",
    "\n",
    "#     if input_range is not None:\n",
    "#         if x.max() > 1 and input_range[1] == 1:\n",
    "#             x = x / 255.0\n",
    "\n",
    "#     return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T19:10:32.634142Z",
     "start_time": "2020-10-20T19:10:32.495800Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "from pydicom.data import get_testdata_files\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "file_path = '../input/rsna-str-pulmonary-embolism-detection/test/00268ff88746/75d23269adbd/012c12fe09c3.dcm'\n",
    "dataset = pydicom.dcmread(file_path)\n",
    "\n",
    "\n",
    "if 'PixelData' in dataset:\n",
    "    rows = int(dataset.Rows)\n",
    "    cols = int(dataset.Columns)\n",
    "    print(\"Image size.......: {rows:d} x {cols:d}, {size:d} bytes\".format(\n",
    "        rows=rows, cols=cols, size=len(dataset.PixelData)))\n",
    "    if 'PixelSpacing' in dataset:\n",
    "        print(\"Pixel spacing....:\", dataset.PixelSpacing)\n",
    "\n",
    "# use .get() if not sure the item exists, and want a default value if missing\n",
    "print(\"Slice location...:\", dataset.get('SliceLocation', \"(missing)\"))\n",
    "\n",
    "# plot the image using matplotlib\n",
    "plt.imshow(dataset.pixel_array, cmap=plt.cm.bone)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('fastbook': conda)",
   "language": "python",
   "name": "python37764bitfastbookconda806f9a725aef497b9b1418421455f8a7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "357.5px",
    "left": "637.014px",
    "right": "20px",
    "top": "480.938px",
    "width": "576.25px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
